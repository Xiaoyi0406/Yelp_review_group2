{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the subdataset \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# read the entire file into a python array\n",
    "with open('/Users/kzhao46/Downloads/628-2/data/review_train.json', 'rb') as f:\n",
    "    data = f.readlines(10000000)\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "(15056, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset:\")\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "Index([u'business_id', u'date', u'stars', u'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names:\")\n",
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of each column:\n",
      "business_id             int64\n",
      "date           datetime64[ns]\n",
      "stars                   int64\n",
      "text                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Datatype of each column:\")\n",
    "print(data_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few dataset entries:\n",
      "   business_id                date  stars  \\\n",
      "0        31292 2013-05-07 04:34:36      1   \n",
      "1        35344 2017-01-14 21:30:33      5   \n",
      "2       152538 2016-11-09 20:09:03      5   \n",
      "3        71871 2018-01-09 20:56:38      5   \n",
      "4        64913 2018-01-30 23:07:38      1   \n",
      "\n",
      "                                                text  \n",
      "0  Total bill for this horrible service? Over $8G...  \n",
      "1  I *adore* Travis at the Hard Rock's new Kelly ...  \n",
      "2  I have to say that this office really has it t...  \n",
      "3  Went in for a lunch. Steak sandwich was delici...  \n",
      "4  Today was my second out of three sessions I ha...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Few dataset entries:\")\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unique words: ', 86244)\n"
     ]
    }
   ],
   "source": [
    "#count the words\n",
    "from collections import Counter\n",
    "\n",
    "text = ' '.join(data_df['text'].tolist())\n",
    "review_word = text.split(' ')\n",
    "all_reviews = ' '.join(review_word)\n",
    "words = all_reviews.split()\n",
    "\n",
    "# words wrong datatype\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "reviews_ints = []\n",
    "for review in review_word:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
    "print('Unique words: ', len((vocab_to_int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unique words: ', 86244)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'the', 65144),\n",
       " (u'and', 54948),\n",
       " (u'I', 41282),\n",
       " (u'a', 39395),\n",
       " (u'to', 38539),\n",
       " (u'was', 28091),\n",
       " (u'of', 22847),\n",
       " (u'is', 19116),\n",
       " (u'for', 18290),\n",
       " (u'in', 16481),\n",
       " (u'The', 13893),\n",
       " (u'it', 13736),\n",
       " (u'with', 13032),\n",
       " (u'my', 12791),\n",
       " (u'that', 12320),\n",
       " (u'but', 10611),\n",
       " (u'on', 10477),\n",
       " (u'have', 9914),\n",
       " (u'you', 9840),\n",
       " (u'this', 9523)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Unique words: ', len((vocab_to_int)))\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "#remove the topwords and punctuations.\n",
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
