{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 628 Module2 report\n",
    "Kangyi Zhao, Yixin Chen, Liyun Zeng, Canyang Liu\n",
    "\n",
    "## Abstract\n",
    "### Motivation \n",
    "We want to make suggestions to new business owners for the purpose of site selection and focus selection on their restaurants. We firstly look at the key elements that influence the operation of restaurants.\n",
    "There are **7 aspects that influence the management of a restaurant**. \n",
    "\n",
    "\n",
    "    1.Product: food and drinks\n",
    "    2.Service: time spent, attitude towards customers\n",
    "    3.publicity: like advertising or public praise\n",
    "    4.target market: pricing strategy and the right location\n",
    "    5.comparing: competitive to a restaurant nearby or in the same class\n",
    "    6.feedback: good online feedback\n",
    "    7.Environment: both inside an environment like decoration or furnish and outside environment, i.e. location\n",
    "    \n",
    "    \n",
    "When we were glancing over the business data, we found lots of restaurants have the same name but at a different location, which should be called the **\"Chain Restaurant\"**. We limited our research on those chain restaurant because this kind of restaurant shares the same product\\publicity\\target market\\comparing, and the only difference should be the **location and service**.\n",
    "\n",
    "\n",
    "**So, what kind of location could influence the operation of a chain restaurant? Do their service really have a significant difference?**\n",
    "\n",
    "\n",
    "The information on the Google Map indicates that a binary classification could be applied to the type of location, that is whether a restaurant is in the business district. The business district is defined by a region that gathers lots of restaurant and shopping malls, which is an interesting area to visit. So intuitively, those restaurants in the business district should run better since they have larger customer flow while they also pay more money on the location they choose.\n",
    "\n",
    "We are going to find out whether the advantage of business district overweighs its cost, using the Yelp review data.\n",
    "\n",
    "### Outline\n",
    "<img src='https://raw.githubusercontent.com/Xiaoyi0406/Yelp_review_group2/master/picture/outline.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analysis of review dataset\n",
    "### Prepreparing Data\n",
    "\n",
    "1. After we transfer the emoticon to English, We detect the language by using package 'langdetect', then delete the comment which not in English.\n",
    "2. Correct acronym, eg: \"can\\'t\" to \"can not\"  \n",
    "3. According to the flowchart, the upper branch is preparing to create the dictionary, the lower branch is preparing to extract the adjectives, adverbs and nouns. \n",
    " \n",
    "<img src='https://raw.githubusercontent.com/Xiaoyi0406/Yelp_review_group2/master/picture/use.png'>\n",
    "\n",
    "### Create the Dictionary \n",
    "1. After we extract the adjectives, adverbs and nouns of each review, we can attach them to their review text respectively. \n",
    "2. We divide the nouns into 2 types by LDA. The first type contains all nouns of food and the other is about service and location.\n",
    "3. We delete useless nouns from each type manually and the rest forms a dictionary for a specific category.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Xiaoyi0406/Yelp_review_group2/master/picture/dic.png' width=600 heigth=300 />\n",
    "\n",
    "\n",
    "#### Notation\n",
    "\n",
    "**LDA:** Because we want to give a score in different aspects, such as food, service and so on. So we decide to use LDA to divide them into aspects. We try the number of aspects several times and find that it works well when it divides into 2 aspects -- the food and the other. The other mainly contains nouns for service and location. So we use LDA to divide into 2 aspects. \n",
    "\n",
    "\n",
    "### Adjective Adverb Noun\n",
    "We try to get matched adjective adverb and noun. At first, we try to get the adj and adv which are closest to the noun, However, it didn't give the relatively accurate result. For instance, the .....Finally, We define the formula according to common sentence pattern, the formula is given by the following picture. It is true that this method achieves high accuracy, but it can only detect about 40% keywords. Considering to train the model to predict the score, the accuracy plays a more important role. \n",
    "\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Xiaoyi0406/Yelp_review_group2/master/picture/word_operation.png' width=500 heigth=240 />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adjective Score Model\n",
    "#### Outline of the model\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Xiaoyi0406/Yelp_review_group2/master/picture/SVM.png'>\n",
    "\n",
    "#### Notation\n",
    "\n",
    "**Dataset**  \n",
    "Since the SVM is computation-consuming and time-consuming, we only extract the 1/4 data as sub-dataset of each star instead of all data.  \n",
    "\n",
    "**Step one - extract the word**  \n",
    "We also try to get all the adj in the review instead of getting the matched adv adj for none in the dictionary, However, the result is not good, the model predicts word \"good\" just 1 star, which is definitely u reasonable, because that method ignore the negative word combined with the adj. \n",
    "\n",
    "**Step two - word2vec**  \n",
    "We use the package 'gensim' to import pre-trained word embedding--GoogleNews-vectors-negative300. Each word can be seen as 300-dimension word embedding. We match the extracted adjective with their word embeddings. Since the existed word embedding is relatively comprehensive. We also treat word embedding of the nonexistent adjective word the mean vector of the word embedding we ready have.  \n",
    "\n",
    "**Step three - SVM train model**  \n",
    "We define the word embedding of the extracted adjective as X_train, the score of review which the word appears as the Y_train. There are the tricky things when we consider Y_train, the sentence shows an adverse attitude if the matched adverb gives negative attitude, so we define 6-score as the Y_train instead.  \n",
    "In training part We try parameter 'C': 1,10, 100, 500, 1e3, 5e3, 1e4, 5e4, 1e5;parameter 'gamma': 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1. Finally, the model with 'C'=500, 'gamma'=0.01 gives the best performence.  \n",
    "\n",
    "**Step four - score adjective**  \n",
    "The model will give the score when you input the special adjective.\n",
    "The score is reasonable, for instance, \"good\",\"excellent\",\"bad\" are respectively given scores 4,5,1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Business\n",
    "#### Outline\n",
    "    1. define the business district\n",
    "    2. classify all the restaurant by business district\n",
    "    3. establish a two-way ANOVA model to find out if there is a significant difference between whether in a business district and the state of the restaurant for \"average review stars\", \"average food score\", and \"average service score\".\n",
    "    \n",
    "**Step one - define the business district**\n",
    "we defined the business district by searching \"shopping mall\" on google map and looked for the boundary of the yellow area on it, which means an interesting area that attracts people. \n",
    "\n",
    "\n",
    "**Step two - classify the restaurant**\n",
    "we used the half-line algorithm to identify whether a restaurant belongs to the business district. The half-line algorithm refers to draw a half line to the left of each data point, find the number of intersection between the half line and the boundary polygon. An odd number means the point is inside the polygon.\n",
    "About 1/4 chain restaurants belong to the business district.\n",
    "\n",
    "**step three - 2-way ANOVA**\n",
    "Since we wanted to find out if there exists a significant difference between 2 treatment, in/out business district, in which state, we decided to establish a 2-way ANOVA model, using 3 criteria, \"average review stars\", \"average food score\", and \"average service score\".\n",
    "\n",
    "For those 27 chain restaurants that we selected (each of which has more than 100 subbranches), we thought they could be divided into 5 types---burger, pizza, coffee, sandwich, and a regional restaurant. Following shows the name of them.\n",
    "    1. burger: McDonald's, Burger King, Wendy's, KFC, Dairy Queen, Popeyes Louisiana Kitchen, Arby's, Five guys, jack in the box, sonic drive\n",
    "    2. pizza: Pizza Hut, Domino's Pizza, Papa John's Pizza, Little Caesar's Pizza, Pizza Pizza\n",
    "    3. coffee: Starbucks, Tim Hortons, Dunkin' Donuts, Panera Bread, Denny's, Second Cup\n",
    "    4. sandwich: Subway, Jimmy John's, Jersey Mike's\n",
    "    5. regional: Taco Bell, Chipotle, Panda Express\n",
    "    \n",
    "**Example: Panera Bread**\n",
    "\n",
    "Here we were going to give a specific example, Panera Bread, to show which kind of suggestion we could give.\n",
    "\n",
    "**The results of ANOVA table**\n",
    "    1. the \"average review star\" is significant in the only state\n",
    "    2. the \"average food score\" is significant in the only state\n",
    "    3. the \"average service score\" is significant in state and business district\n",
    "    \n",
    "**Analysis**\n",
    "\n",
    "The ANOVA table indicates that, if the Panera Bread's owners want to receive higher reviews, they should run their Panera Bread in NV state and ON state. Since the business district effect is not significant, they don't have to run their business in that area, so that they could save a large amount of money.\n",
    "\n",
    "In addition, the \"average service score\" indicates that there exists a significant effect of the business district, and the data shows that the Panera Bread in the business district could gain higher service score. \n",
    "\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "In total, we would suggest the potential owners of Panera Bread run a new business in NV and ON state, the business district is unnecessary and costly. We would also suggest the owners of Panera Bread pay more attention to the service than food because the food quality couldn't differentiate Panera Bread between inside and outside the business district, but service does. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model\n",
    "\n",
    "### Outline\n",
    "\n",
    "In the process of predicting the score of review, we train a LSTM model and use 200,000 training data. Finally we get mse of 0.84.\n",
    "\n",
    "### Naive Bayes Model\n",
    "\n",
    "#### Train Model\n",
    "After split the text we get from data cleaning step, we can get a list of word list. We regrad every word as feature. Then we can create an array. The rows of this array represent samples. And the columns represent all words. The value of the element is 0 or 1. \n",
    "\n",
    "Thus we choose Bernoulli Naive Bayes method to fit the model. We use **BernoulliNB** function imported from package of **sklearn.naive_bayes** .[1]\n",
    "\n",
    "#### Result\n",
    "Using this method, we'll create a large array. The number of column equals to the number of unique words in the text. So when we try to train the model on a large training data set, this method will be time cosuming. Also, after we apply it on our data set, we found that the model didn't work well.\n",
    "\n",
    "### LSTM Model\n",
    "\n",
    "#### Train Model\n",
    "To train the data using LSTM model, we create an array with maximum number of column of 150. The rows represent samples. And the columns represent words in samples. The value of every elements represents the word index in a given word dictionary in this sample.\n",
    "\n",
    "We use four layers here. The first one is the Embedding layer. The two layers of LSTM. And the last is the Dense layer. We use functions of **Sequential**, **Embedding**, **LSTM**, **Dense** imported from packages of **keras.models**, **keras.layers** and **keras.layers.embeddings**.[2-5]\n",
    "\n",
    "#### Result\n",
    "LSTM model works well and faster than naive bayes model. And we finally get the mse of 0.84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "### Advantage & Disadvantage \n",
    "\n",
    "#### Advantage\n",
    "1. **Detailed suggestion**: We extract the useful none and matched adj and adv and create a model to predict the score of adj , which helps us to get the deep insight of the specific restaurant of detailed aspects, like which kind of food is bad, what service is popular.\n",
    "2. **General suggestion**: We use ANOVA to find the significance of state effect and business district effect, which could insight enlighten the business owners to decide either food or service deserves more attention, and also enlighten the potential owners to select a site for their new restaurant.\n",
    "3. **Shiny App**: We also create the shiny app to give the direct presentation for the business analysis, the link is as follows,https://lzeng32.shinyapps.io/Yelp_suggestions/ more explanation from README file.\n",
    "\n",
    "#### Disadvantage\n",
    "\n",
    "1. **Not high-accurate dictionary**: For the Dictionary part we use LDA to sperate the food and service, However, It can not give us a high-accuarte result, the are some same word and adj word inside the dictionary, even their just take a 10% of the dictionary. \n",
    "2. **Only 45% useful tuple**: We'd like to extract all the none from dictionary matched with adj and adv, but the structure of senstence is really complex, we define the formular, it can only extract about 45% of useful information, the sentences like \"I like the food which is almost the best one I have had before.\" can not be used due to the limitation\n",
    "\n",
    "\n",
    "### Future work\n",
    "Due to time reason, we only tried to figure out which aspect deserves more attention but didn't know how to perfect it. If time permits, we would do deeper research to compare the frequency of the nouns of food and service and its adjective between inside and outside the business district to give more detailed suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Scikit-learn.org. (n.d.). 1.9. Naive Bayes — scikit-learn 0.20.3 documentation. [online] Available at: https://scikit-learn.org/stable/modules/naive_bayes.html.\n",
    "2. Brownlee, J. (2016). Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras. [online] Machine Learning Mastery. Available at: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/.\n",
    "3. Kaggle.com. (n.d.). Simple LSTM for text classification | Kaggle. [online] Available at: https://www.kaggle.com/kredy10/simple-lstm-for-text-classification.\n",
    "4. Kaggle.com. (n.d.). Simple LSTM for text classification | Kaggle. [online] Available at: https://www.kaggle.com/kredy10/simple-lstm-for-text-classification.\n",
    "5. Ahamed, S. (2018). Text Classification Using LSTM and visualize Word Embeddings: Part-1. [online] Medium. Available at: https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conribution\n",
    "**Kangyi Zhao:**  The main part of prepreparing Data and score model, help to make the shiny app and summarize the report.  \n",
    "**Yixin Chen:** The main part of prediction model and Kaggle, help to make the slide and summarize the report.  \n",
    "**Liyun Zeng:** The main part of dictionary and shiny app, help to make the slide and summarize the report.  \n",
    "**Canyang Liu:** The main part of getting the useful dataset, make the anova table to analyize the data and make the slide, help to summarize the report. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
